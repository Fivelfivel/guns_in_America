{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>aid</th>\n",
       "      <th>paper</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fox0</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Adam Carrington']</td>\n",
       "      <td>2018-03-03 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/opinion/2018/03/03/supr...</td>\n",
       "      <td>The debate about how to deal with guns in our ...</td>\n",
       "      <td>['debate', 'deal', 'gun', 'country', 'rage', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fox1</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Kaitlyn Schallhorn', '- Jonas Oransky', 'Eve...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/politics/2018/03/01/gun...</td>\n",
       "      <td>In the weeks after a gunman walked into a high...</td>\n",
       "      <td>['week', 'gunman', 'walked', 'high', 'school',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fox2</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Kathleen Joyce']</td>\n",
       "      <td>2018-03-03 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/us/2018/03/03/cmu-stude...</td>\n",
       "      <td>The 19-year-old student suspected of killing h...</td>\n",
       "      <td>['19-year-old', 'student', 'suspected', 'killi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>fox4</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Gregg Re']</td>\n",
       "      <td>2018-03-02 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/politics/2018/03/02/tru...</td>\n",
       "      <td>Just one day after putting the NRA on the defe...</td>\n",
       "      <td>['one', 'day', 'putting', 'nra', 'defensive', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>fox5</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Brooke Singman', '- President Trump']</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/politics/2018/03/01/tru...</td>\n",
       "      <td>President Trump has touched off new tensions w...</td>\n",
       "      <td>['president', 'trump', 'ha', 'touched', 'new',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   aid paper                                             author  \\\n",
       "0           0  fox0   fox                                ['Adam Carrington']   \n",
       "1           1  fox1   fox  ['Kaitlyn Schallhorn', '- Jonas Oransky', 'Eve...   \n",
       "2           2  fox2   fox                                 ['Kathleen Joyce']   \n",
       "3           4  fox4   fox                                       ['Gregg Re']   \n",
       "4           5  fox5   fox            ['Brooke Singman', '- President Trump']   \n",
       "\n",
       "                  date                                                url  \\\n",
       "0  2018-03-03 00:00:00  http://www.foxnews.com/opinion/2018/03/03/supr...   \n",
       "1  2018-03-01 00:00:00  http://www.foxnews.com/politics/2018/03/01/gun...   \n",
       "2  2018-03-03 00:00:00  http://www.foxnews.com/us/2018/03/03/cmu-stude...   \n",
       "3  2018-03-02 00:00:00  http://www.foxnews.com/politics/2018/03/02/tru...   \n",
       "4  2018-03-01 00:00:00  http://www.foxnews.com/politics/2018/03/01/tru...   \n",
       "\n",
       "                                             content  \\\n",
       "0  The debate about how to deal with guns in our ...   \n",
       "1  In the weeks after a gunman walked into a high...   \n",
       "2  The 19-year-old student suspected of killing h...   \n",
       "3  Just one day after putting the NRA on the defe...   \n",
       "4  President Trump has touched off new tensions w...   \n",
       "\n",
       "                                       clean_content  \n",
       "0  ['debate', 'deal', 'gun', 'country', 'rage', '...  \n",
       "1  ['week', 'gunman', 'walked', 'high', 'school',...  \n",
       "2  ['19-year-old', 'student', 'suspected', 'killi...  \n",
       "3  ['one', 'day', 'putting', 'nra', 'defensive', ...  \n",
       "4  ['president', 'trump', 'ha', 'touched', 'new',...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleandataset.csv', header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment analyzer\n",
    "def sentanal(tokens):\n",
    "    sents=[]\n",
    "    for tok in tokens:\n",
    "        blob=TextBlob(tok, analyzer=NaiveBayesAnalyzer())\n",
    "        sents.append(blob.sentiment)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze just the first line of each article\n",
    "#this could and probably should be much faster!!!\n",
    "s1=[]\n",
    "for cont in df['content']:\n",
    "    myl=cont.split('.')\n",
    "    line1=myl[0]\n",
    "    s1.append(line1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-139cf74a96cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmysent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentanal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-a51bb297dcac>\u001b[0m in \u001b[0;36msentanal\u001b[0;34m(tokens)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mblob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0msents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/textblob/decorators.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/textblob/blob.py\u001b[0m in \u001b[0;36msentiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnamedtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mform\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjectivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \"\"\"\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcached_property\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \"\"\"\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Lazily train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNaiveBayesAnalyzer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_punc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mfiltered\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/textblob/base.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# Lazily train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Analyze text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/textblob/decorators.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m             nltk.corpus.movie_reviews.words(fileids=[f])), 'neg') for f in neg_ids]\n\u001b[1;32m     78\u001b[0m         pos_feats = [(self.feature_extractor(\n\u001b[0;32m---> 79\u001b[0;31m             nltk.corpus.movie_reviews.words(fileids=[f])), 'pos') for f in pos_ids]\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_feats\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m             nltk.corpus.movie_reviews.words(fileids=[f])), 'neg') for f in neg_ids]\n\u001b[1;32m     78\u001b[0m         pos_feats = [(self.feature_extractor(\n\u001b[0;32m---> 79\u001b[0;31m             nltk.corpus.movie_reviews.words(fileids=[f])), 'pos') for f in pos_ids]\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_feats\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpos_feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36m_default_feature_extractor\u001b[0;34m(words)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_feature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m\"\"\"Default feature extractor for the NaiveBayesAnalyzer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/textblob/en/sentiments.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_feature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m\"\"\"Default feature extractor for the NaiveBayesAnalyzer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/util.py\u001b[0m in \u001b[0;36miterate_from\u001b[0;34m(self, start_tok)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;31m# Open the stream, if it's not open already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;31m# If the file is empty, the while loop will never run.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/util.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \"\"\"\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPathPointer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             self._stream = SeekableUnicodeStreamReader(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, encoding)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeekableUnicodeStreamReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mysent=sentanal(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentiment(classification='pos', p_pos=0.9954586638537127, p_neg=0.004541336146284627),\n",
       " Sentiment(classification='neg', p_pos=0.23682905598571363, p_neg=0.763170944014283),\n",
       " Sentiment(classification='pos', p_pos=0.8995924032002689, p_neg=0.10040759679973492),\n",
       " Sentiment(classification='pos', p_pos=0.9989310360900759, p_neg=0.0010689639099280633),\n",
       " Sentiment(classification='pos', p_pos=0.9992331286327895, p_neg=0.000766871367211887)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect\n",
    "mysent[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe out of the results\n",
    "#is there a better way to do this - more directly? Omit the listing step?\n",
    "sentlist=[]\n",
    "poslist=[]\n",
    "neglist=[]\n",
    "for item in mysent:\n",
    "    sentlist.append(item.classification)\n",
    "    poslist.append(item.p_pos)\n",
    "    neglist.append(item.p_neg)\n",
    "df['sent']=sentlist\n",
    "df['p_pos']=poslist\n",
    "df['p_neg']=neglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>aid</th>\n",
       "      <th>paper</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>sent</th>\n",
       "      <th>p_pos</th>\n",
       "      <th>p_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fox0</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Adam Carrington']</td>\n",
       "      <td>2018-03-03 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/opinion/2018/03/03/supr...</td>\n",
       "      <td>The debate about how to deal with guns in our ...</td>\n",
       "      <td>['debate', 'deal', 'gun', 'country', 'rage', '...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.995459</td>\n",
       "      <td>0.004541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fox1</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Kaitlyn Schallhorn', '- Jonas Oransky', 'Eve...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/politics/2018/03/01/gun...</td>\n",
       "      <td>In the weeks after a gunman walked into a high...</td>\n",
       "      <td>['week', 'gunman', 'walked', 'high', 'school',...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.236829</td>\n",
       "      <td>0.763171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fox2</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Kathleen Joyce']</td>\n",
       "      <td>2018-03-03 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/us/2018/03/03/cmu-stude...</td>\n",
       "      <td>The 19-year-old student suspected of killing h...</td>\n",
       "      <td>['19-year-old', 'student', 'suspected', 'killi...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.899592</td>\n",
       "      <td>0.100408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>fox4</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Gregg Re']</td>\n",
       "      <td>2018-03-02 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/politics/2018/03/02/tru...</td>\n",
       "      <td>Just one day after putting the NRA on the defe...</td>\n",
       "      <td>['one', 'day', 'putting', 'nra', 'defensive', ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.998931</td>\n",
       "      <td>0.001069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>fox5</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Brooke Singman', '- President Trump']</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/politics/2018/03/01/tru...</td>\n",
       "      <td>President Trump has touched off new tensions w...</td>\n",
       "      <td>['president', 'trump', 'ha', 'touched', 'new',...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>0.000767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ind   aid paper                                             author  \\\n",
       "0    0  fox0   fox                                ['Adam Carrington']   \n",
       "1    1  fox1   fox  ['Kaitlyn Schallhorn', '- Jonas Oransky', 'Eve...   \n",
       "2    2  fox2   fox                                 ['Kathleen Joyce']   \n",
       "3    4  fox4   fox                                       ['Gregg Re']   \n",
       "4    5  fox5   fox            ['Brooke Singman', '- President Trump']   \n",
       "\n",
       "                  date                                                url  \\\n",
       "0  2018-03-03 00:00:00  http://www.foxnews.com/opinion/2018/03/03/supr...   \n",
       "1  2018-03-01 00:00:00  http://www.foxnews.com/politics/2018/03/01/gun...   \n",
       "2  2018-03-03 00:00:00  http://www.foxnews.com/us/2018/03/03/cmu-stude...   \n",
       "3  2018-03-02 00:00:00  http://www.foxnews.com/politics/2018/03/02/tru...   \n",
       "4  2018-03-01 00:00:00  http://www.foxnews.com/politics/2018/03/01/tru...   \n",
       "\n",
       "                                             content  \\\n",
       "0  The debate about how to deal with guns in our ...   \n",
       "1  In the weeks after a gunman walked into a high...   \n",
       "2  The 19-year-old student suspected of killing h...   \n",
       "3  Just one day after putting the NRA on the defe...   \n",
       "4  President Trump has touched off new tensions w...   \n",
       "\n",
       "                                       clean_content sent     p_pos     p_neg  \n",
       "0  ['debate', 'deal', 'gun', 'country', 'rage', '...  pos  0.995459  0.004541  \n",
       "1  ['week', 'gunman', 'walked', 'high', 'school',...  neg  0.236829  0.763171  \n",
       "2  ['19-year-old', 'student', 'suspected', 'killi...  pos  0.899592  0.100408  \n",
       "3  ['one', 'day', 'putting', 'nra', 'defensive', ...  pos  0.998931  0.001069  \n",
       "4  ['president', 'trump', 'ha', 'touched', 'new',...  pos  0.999233  0.000767  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is too big - drop the content\n",
    "df=df.drop('content', axis=1)\n",
    "df=df.drop('clean_content', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind</th>\n",
       "      <th>aid</th>\n",
       "      <th>paper</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>sent</th>\n",
       "      <th>p_pos</th>\n",
       "      <th>p_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fox0</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Adam Carrington']</td>\n",
       "      <td>2018-03-03 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/opinion/2018/03/03/supr...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.995459</td>\n",
       "      <td>0.004541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fox1</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Kaitlyn Schallhorn', '- Jonas Oransky', 'Eve...</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/politics/2018/03/01/gun...</td>\n",
       "      <td>neg</td>\n",
       "      <td>0.236829</td>\n",
       "      <td>0.763171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fox2</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Kathleen Joyce']</td>\n",
       "      <td>2018-03-03 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/us/2018/03/03/cmu-stude...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.899592</td>\n",
       "      <td>0.100408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>fox4</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Gregg Re']</td>\n",
       "      <td>2018-03-02 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/politics/2018/03/02/tru...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.998931</td>\n",
       "      <td>0.001069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>fox5</td>\n",
       "      <td>fox</td>\n",
       "      <td>['Brooke Singman', '- President Trump']</td>\n",
       "      <td>2018-03-01 00:00:00</td>\n",
       "      <td>http://www.foxnews.com/politics/2018/03/01/tru...</td>\n",
       "      <td>pos</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>0.000767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ind   aid paper                                             author  \\\n",
       "0    0  fox0   fox                                ['Adam Carrington']   \n",
       "1    1  fox1   fox  ['Kaitlyn Schallhorn', '- Jonas Oransky', 'Eve...   \n",
       "2    2  fox2   fox                                 ['Kathleen Joyce']   \n",
       "3    4  fox4   fox                                       ['Gregg Re']   \n",
       "4    5  fox5   fox            ['Brooke Singman', '- President Trump']   \n",
       "\n",
       "                  date                                                url  \\\n",
       "0  2018-03-03 00:00:00  http://www.foxnews.com/opinion/2018/03/03/supr...   \n",
       "1  2018-03-01 00:00:00  http://www.foxnews.com/politics/2018/03/01/gun...   \n",
       "2  2018-03-03 00:00:00  http://www.foxnews.com/us/2018/03/03/cmu-stude...   \n",
       "3  2018-03-02 00:00:00  http://www.foxnews.com/politics/2018/03/02/tru...   \n",
       "4  2018-03-01 00:00:00  http://www.foxnews.com/politics/2018/03/01/tru...   \n",
       "\n",
       "  sent     p_pos     p_neg  \n",
       "0  pos  0.995459  0.004541  \n",
       "1  neg  0.236829  0.763171  \n",
       "2  pos  0.899592  0.100408  \n",
       "3  pos  0.998931  0.001069  \n",
       "4  pos  0.999233  0.000767  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the sentiments out\n",
    "outfile = open('sentiments.csv', 'w')\n",
    "df.to_csv(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
